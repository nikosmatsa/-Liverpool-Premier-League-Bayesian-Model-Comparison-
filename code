

# load libraries 
library(rstan)
library(loo)


# Liverpool's Data Premier League scores 2018-2019
liverpool = c(4,2,1,2,2,3,1,0,1,4,1,2,3,1,3,4,3,2,4,5,1,1,4,1,1,3,0,5,0,4,2,2,3,2,2,5,3,2)
length(liverpool)
mean(liverpool)
var(liverpool)


# estimating Gamma parameters given the mean and the var of the data 
estGammaParams <- function(mu, var) {
  alpha <- mu^2 / var 
  beta <-  mu  /  var
  return(params = list(alpha = alpha, beta = beta))
}
# gamma parameters to pass in gamma prior 
estGammaParams(2.25,1.125)


# 1st model of Log Poisson-Gamma Model 
liv ="data {
  int N;
  int y[N];
}parameters {
  real<lower=0> lambda;
}model {  
  lambda ~ gamma(4.5,2);
  y ~ poisson(lambda);
}
generated quantities {
 vector[N] log_lik;
  for (n in 1:N) {
  log_lik[n] = poisson_lpmf(y[N] | lambda);
}} "

# data as a list ALWAYS 
stan.dat <- list(N = length(liverpool),y = liverpool)

# fit the sampling model to HMC 
fit <- stan(model_code  = liv,
             data       = stan.dat,
             iter       = 2000, 
             chains     = 4,
             seed       = 12345,
             control    = list(adapt_delta=0.9))

# print posterior mean of lambda parameter 
print(fit,pars = "lambda")

# plot parameter 
plot(fit,pars = "lambda")

# extract log_lik from posterior samples 
log_lik_1 <- extract_log_lik(fit,
                             parameter_name = "log_lik",
                             merge_chains = FALSE)
r_eff1 <- relative_eff(exp(log_lik_1)) 
loo_1 <- loo(log_lik_1, r_eff = r_eff1, cores = 4)

print(loo_1)
plot(loo_1)


# 2nd model of Log Poisson-Normal Model 
liv2 ="data {
  int N;
  int y[N];
}parameters {
  real<lower=0> lambda;
}model {  
  lambda ~ normal(2,0.5);
  y ~ poisson(lambda);
}
generated quantities {
 vector[N] log_lik;
  for (n in 1:N) {
  log_lik[n] = poisson_lpmf(y[N] | lambda);
}} "

# data as a list ALWAYS 
stan.dat <- list(N = length(liverpool),y = liverpool)

# fit the sampling model to HMC 
fit2 <- stan(model_code = liv2,
            data = stan.dat,
            iter = 2000, 
            chains = 4,
            seed = 12345,
            control = list(adapt_delta=0.99))

# print posterior mean of lambda parameter 
print(fit2,pars = "lambda")
# plot parameter 
plot(fit2,pars = "lambda")
# extract log_lik from posterior samples 
log_lik_2 <- extract_log_lik(fit2,
                            parameter_name = "log_lik",
                             merge_chains = FALSE)
r_eff2 <- relative_eff(exp(log_lik_2)) 
loo_2 <- loo(log_lik_2, r_eff = r_eff2, cores = 4)
print(loo_2)
plot(loo_2)


# comparing the two predictive accuracies of the models 
comp <- loo_compare(loo_1, loo_2)
print(comp)
# When that difference, elpd_diff, is positive then the expected predictive
# accuracy for the second model is higher. 
# A negative elpd_diff favors the first model.
# In our case model2 with log poisson-normal has 
# a better expected predictive accuracy and it's 
# better that the first with log poisson-gamma model 








